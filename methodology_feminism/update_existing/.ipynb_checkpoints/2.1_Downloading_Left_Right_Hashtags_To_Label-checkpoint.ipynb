{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49293ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76969ce",
   "metadata": {},
   "source": [
    "**Manual Input**: Set the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e063b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/acoub/OneDrive/Desktop/DSDM/Thesis/ChileGov/methodology_feminism'\n",
    "sep='/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c547e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_scripts = path+sep+'update_existing'\n",
    "path_data= path+sep+'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8dffa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = path_data+sep+'final_data_set.sav'\n",
    "df_old = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdfde1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = path_data+sep+'final_data_set_update.sav'\n",
    "df_updated = pickle.load(open(file, 'rb'))\n",
    "\n",
    "file = path_data+sep+'left_hashtags_for_label.sav'\n",
    "left_hashtags = pickle.load(open(file, 'rb'))\n",
    "\n",
    "file = path_data+sep+'right_hashtags_for_label.sav'\n",
    "right_hashtags = pickle.load(open(file, 'rb'))\n",
    "\n",
    "file = path_data+sep+'start_date_for_label.sav'\n",
    "start_date= pickle.load(open(file, 'rb'))\n",
    "\n",
    "file = path_data+sep+'end_date_for_label.sav'\n",
    "end_date= pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90dca907",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_string=\"(\"\n",
    "for hashtag in (left_hashtags+right_hashtags):\n",
    "    hashtag_string+=hashtag + \" OR \"\n",
    "hashtag_string=hashtag_string[:len(hashtag_string)-4]+\")\"\n",
    "\n",
    "authors_old=list(df_old['author.username'])\n",
    "authors_old = list(set(authors_old))\n",
    "\n",
    "authors_updated=list(df_updated['author.username'])\n",
    "authors_updated = list(set(authors_updated))\n",
    "\n",
    "# We left only the authors that we don't have previusly labeled\n",
    "for author in authors_updated:\n",
    "    if author in authors_old:\n",
    "        authors_updated.remove(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06019b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path_data+sep+'new_authors.sav'\n",
    "pickle.dump((authors_updated), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ca2f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text= hashtag_string\n",
    "queries_list=[]\n",
    "query_from_good=\"\"\n",
    "query_from_test=\"\"\n",
    "\n",
    "for author in authors_updated:\n",
    "    query_from_test+=\"from: \" + author + \" OR \"\n",
    "    if len(query_text + query_from_test) + 3 <= 1024:\n",
    "        query_from_good = query_from_test\n",
    "    else:\n",
    "        queries_list.append(\"(\"+query_from_good[:len(query_from_good)-4]+\")\"+ query_text)\n",
    "        query_from_good=\"from: \" + author + \" OR \"\n",
    "        query_from_test=\"from: \" + author + \" OR \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4a7abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(queries_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f15728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data+sep+'search_for_labels_new_authors.txt', 'w') as f:\n",
    "    for line in queries_list:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c1413",
   "metadata": {},
   "source": [
    "**Manual revision:** Run the following two cells to know the total number of tweets to download and see if does not exceed the limit of your twarc acount. If is OK run also the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c29f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acoub\\OneDrive\\Desktop\\DSDM\\Thesis\\Methodology\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | Processed 0/12 lines of input file [00:00<?, ?it/s]\n",
      " 17%|#6        | Processed 2/12 lines of input file [00:02<00:13,  1.37s/it]\n",
      " 25%|##5       | Processed 3/12 lines of input file [00:05<00:17,  1.93s/it]\n",
      " 33%|###3      | Processed 4/12 lines of input file [00:08<00:17,  2.18s/it]\n",
      " 42%|####1     | Processed 5/12 lines of input file [00:10<00:16,  2.34s/it]\n",
      " 50%|#####     | Processed 6/12 lines of input file [00:13<00:14,  2.43s/it]\n",
      " 58%|#####8    | Processed 7/12 lines of input file [00:15<00:12,  2.48s/it]\n",
      " 67%|######6   | Processed 8/12 lines of input file [00:18<00:10,  2.55s/it]\n",
      " 75%|#######5  | Processed 9/12 lines of input file [00:21<00:07,  2.58s/it]\n",
      " 83%|########3 | Processed 10/12 lines of input file [00:23<00:05,  2.58s/it]\n",
      " 92%|#########1| Processed 11/12 lines of input file [00:26<00:02,  2.59s/it]\n",
      "100%|##########| Processed 12/12 lines of input file [00:29<00:00,  2.59s/it]\n",
      "100%|##########| Processed 12/12 lines of input file [00:31<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "file=path_data+sep+'search_for_labels_new_authors.txt'\n",
    "%cd {path_data}\n",
    "! twarc2 searches --archive --counts-only --granularity day --start-time {start_date} --end-time {end_date} {file} up_labels_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d468bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets to download: 19106\n"
     ]
    }
   ],
   "source": [
    "count=pd.read_csv(path_data+sep+'up_labels_count.csv',encoding = \"ISO-8859-1\")\n",
    "print(\"Tweets to download: \"+str(count['day_count'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089202c0",
   "metadata": {},
   "source": [
    "**Download the tweets:** (Only if you have enought limit in your twarc account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac75cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acoub\\OneDrive\\Desktop\\DSDM\\Thesis\\Methodology\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | Processed 0/12 lines of input file [00:00<?, ?it/s]\n",
      " 17%|#6        | Processed 2/12 lines of input file [01:01<05:08, 30.84s/it]\n",
      " 25%|##5       | Processed 3/12 lines of input file [01:42<05:14, 34.95s/it]\n",
      " 33%|###3      | Processed 4/12 lines of input file [02:18<04:42, 35.36s/it]\n",
      " 42%|####1     | Processed 5/12 lines of input file [03:07<04:41, 40.17s/it]\n",
      " 50%|#####     | Processed 6/12 lines of input file [03:37<03:41, 36.86s/it]\n",
      " 58%|#####8    | Processed 7/12 lines of input file [04:25<03:21, 40.22s/it]\n",
      " 67%|######6   | Processed 8/12 lines of input file [04:42<02:12, 33.02s/it]\n",
      " 75%|#######5  | Processed 9/12 lines of input file [06:26<02:45, 55.07s/it]\n",
      " 83%|########3 | Processed 10/12 lines of input file [06:44<01:27, 43.52s/it]\n",
      " 92%|#########1| Processed 11/12 lines of input file [07:06<00:37, 37.23s/it]\n",
      "100%|##########| Processed 12/12 lines of input file [07:34<00:00, 34.44s/it]\n",
      "100%|##########| Processed 12/12 lines of input file [08:26<00:00, 42.18s/it]\n"
     ]
    }
   ],
   "source": [
    "%cd {path_data}\n",
    "! twarc2 searches --archive --start-time {start_date} --end-time {end_date} {file} up_right_left_hashtags.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfe459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
