{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ae6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twarc_csv import DataFrameConverter\n",
    "from twarc.expansions import ensure_flattened\n",
    "import pandas as pd\n",
    "from twarc_csv import dataframe_converter\n",
    "from twarc_csv import CSVConverter, DataFrameConverter\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ead8de",
   "metadata": {},
   "source": [
    "**Manual Input**: Set the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/acoub/OneDrive/Desktop/DSDM/Thesis/Methodology'\n",
    "sep='/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210d71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_scripts = path+sep+'new_topic'\n",
    "path_data= path+sep+'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DataFrameConverter()\n",
    "data = []\n",
    "with open(path_data+sep\"right_left_hashtags.json\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "df = converter.process(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=list(df['author.username'])\n",
    "authors = list(set(authors))\n",
    "print(len(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43461a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_retrieve(df):\n",
    "    \"\"\"\n",
    "    df : dataframe of tweets\n",
    "    Description: \n",
    "        The function takes as an object a df of tweets obtained via twarc and \n",
    "        returns a generator object.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    for line, id in zip(df['entities.hashtags'], df['id']):\n",
    "        if pd.isna(line):\n",
    "            continue\n",
    "        line = line.strip()\n",
    "        data = json.loads(line)\n",
    "        for hashtag in ensure_flattened(data):\n",
    "            yield [hashtag['tag'], id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bdab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_df = pd.DataFrame(list(hash_retrieve(df)),\n",
    "                 columns=['tweet_hashtags', 'id'])\n",
    "\n",
    "hashtags_df = hashtags_df.groupby('id')['tweet_hashtags'].apply(lambda x: ','.join(x))\n",
    "df = df.merge(hashtags_df, how='left', left_on='id', right_on='id')\n",
    "df['tweet_hashtags']=df['tweet_hashtags'].str.lower()\n",
    "\n",
    "hasht=[]\n",
    "for i in df.index:\n",
    "    try:\n",
    "        hasht.append(df['tweet_hashtags'][i].split(\",\"))\n",
    "    except:\n",
    "        hasht.append([])\n",
    "    \n",
    "    \n",
    "df['list_hashtags']=hasht\n",
    "\n",
    "hashtags=[]\n",
    "for i in df.index:\n",
    "    hashtags+=list(df['list_hashtags'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d71180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count = Counter(hashtags)\n",
    "  \n",
    "most_occur = count.most_common(100)\n",
    "  \n",
    "print(most_occur)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e2dc8f",
   "metadata": {},
   "source": [
    "### Count the number of left and right hashtgas per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2918825",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = path_data+sep+'hashtags_for_label.sav'\n",
    "left_hashtags,right_hashtags = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each left hashtags we put a 1 to each tweet that use this hashtag\n",
    "for hashtag in left_hashtags:\n",
    "    df_hash=pd.DataFrame()\n",
    "    df_hash=df.dropna(subset=['tweet_hashtags']).copy()\n",
    "    df_hash=df_hash[df_hash.tweet_hashtags.str.contains(hashtag)]\n",
    "    df_hash['count_left_'+str(hashtag)]=1\n",
    "    df=df.merge(df_hash[['id','count_left_'+str(hashtag)]],how=\"left\",on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f600b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We sum for all the hashtags.\n",
    "df['count_left']=0\n",
    "for hashtag in left_hashtags:\n",
    "    try:\n",
    "        df[['count_left_'+str(hashtag)]]=df[['count_left_'+str(hashtag)]].fillna(0)\n",
    "        df['count_left']+=df['count_left_'+str(hashtag)]\n",
    "    except:\n",
    "        print(\"No use of hashtag: \" + hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba730740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the same for right hashtags\n",
    "for hashtag in right_hashtags:\n",
    "    df_hash=pd.DataFrame()\n",
    "    df_hash=df.dropna(subset=['tweet_hashtags']).copy()\n",
    "    df_hash=df_hash[df_hash.tweet_hashtags.str.contains(hashtag)]\n",
    "    df_hash['count_right_'+str(hashtag)]=1\n",
    "    df=df.merge(df_hash[['id','count_right_'+str(hashtag)]],how=\"left\",on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd660baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_right']=0\n",
    "for hashtag in right_hashtags:\n",
    "    try:\n",
    "        df[['count_right_'+str(hashtag)]]=df[['count_right_'+str(hashtag)]].fillna(0)\n",
    "        df['count_right']+=df['count_right_'+str(hashtag)]\n",
    "    except:\n",
    "        print(\"No use of hashtag: \" + hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36a1333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we group by author, to know all the hashtags that each user used.\n",
    "hashtags_per_author=df[['author.username','count_right','count_left']].groupby('author.username').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd87d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_per_author.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f0f20",
   "metadata": {},
   "source": [
    "### Labeling users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the % of right and left hashtags per user\n",
    "hashtags_per_author['percentage_right']=hashtags_per_author['count_right'].astype(float)/(hashtags_per_author['count_right'].astype(float)+hashtags_per_author['count_left'].astype(float))\n",
    "hashtags_per_author['percentage_left']=hashtags_per_author['count_left'].astype(float)/(hashtags_per_author['count_right'].astype(float)+hashtags_per_author['count_left'].astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab98b8",
   "metadata": {},
   "source": [
    "To label user we define thresholds. More than 40 hashtags for the affiliation and also over 80% of hashtags of this affiliation.\n",
    "  \n",
    "**Manual input:** You can change this threshold depending on how strict do you want to be with the criterium. Higher threshold produce less authors with labels, but more sure that the labels are correct. The proportion have to be higher than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814338ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_per_author['Label']=\"None\"\n",
    "hashtags_per_author['Label'][(hashtags_per_author.percentage_right>0.8)&(hashtags_per_author.count_right>40)]=\"Right\"\n",
    "hashtags_per_author['Label'][(hashtags_per_author.percentage_left>0.8)&(hashtags_per_author.count_left>40)]=\"Left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags_per_author['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we merge with the original data set to review a random sample of tweets\n",
    "df=df.merge(hashtags_per_author[[\"Label\"]],how=\"left\",on=\"author.username\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405803ef",
   "metadata": {},
   "source": [
    "### Review a random sample of right and left tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de77fb",
   "metadata": {},
   "source": [
    "**Manual revision:** Here you can review a random sample of tweets during the electoral campaign for users label as right and left to have an idea of the accuracy. If a significant number of tweets looks bad labeled, we recomend to increase the previous thresholds.\n",
    "  \n",
    "First cell is random revision for right wing and second cell is random revision for left wing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c5b704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "df_right=df[df.Label==\"Right\"]\n",
    "number_of_tweets=40\n",
    "indexes=list(df_right.index)\n",
    "for i in range(0,number_of_tweets): \n",
    "    a=random.choice(indexes)\n",
    "    print(df_right['text'][a])\n",
    "    print(\"\")\n",
    "    indexes.remove(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left=df[df.Label==\"Left\"]\n",
    "number_of_tweets=40\n",
    "indexes=list(df_left.index)\n",
    "for i in range(0,number_of_tweets): \n",
    "    a=random.choice(indexes)\n",
    "    print(df_left['text'][a])\n",
    "    print(df_left['author.username'][a])\n",
    "    print(\"\")\n",
    "    indexes.remove(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a data set only with the labels\n",
    "final_df_with_label=pd.DataFrame()\n",
    "filtered_df=hashtags_per_author[(hashtags_per_author.Label==\"Left\")|(hashtags_per_author.Label==\"Right\")]\n",
    "final_df_with_label['author.username']=filtered_df.index\n",
    "final_df_with_label['Label']=list(filtered_df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_with_label['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "filename = path_data+sep+'labeled_users.sav'\n",
    "pickle.dump((final_df_with_label), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb00110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating our data set with the labels.\n",
    "file = path_data+sep+'final_data_set.sav'\n",
    "df = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f171ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.merge(final_df_with_label[['Label','author.username']],how='left',by='author.username')\n",
    "df['Label']=df['Label'].fillna(\"Unlabeled\")\n",
    "filename = path_data+sep+'final_data_set.sav'\n",
    "pickle.dump((df), open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
