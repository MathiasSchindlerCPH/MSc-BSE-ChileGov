{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f383a2",
   "metadata": {},
   "source": [
    "## Downloading all the related tweets from our final list of authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05120480",
   "metadata": {},
   "source": [
    "Now that we cleaned our authors lefting mostly chilean ones, we will go to download all the tweets from this authors that are related with our topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32f7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc00879",
   "metadata": {},
   "source": [
    "**Manual input:** Set the path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87121871",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/acoub/OneDrive/Desktop/DSDM/Thesis/Methodology'\n",
    "sep='/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353643a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_scripts = path+sep+'new_topic'\n",
    "path_data= path+sep+'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = path_data+sep+'keywords.sav'\n",
    "list_of_words=pickle.load(open(file, 'rb'))\n",
    "\n",
    "filename = path_data+sep+'first_search_dates.sav'\n",
    "start_date,end_date=pickle.load(open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69887674",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = path_data+sep+'filtered_by_location.sav'\n",
    "df = pickle.load(open(file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b818972",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors=list(df['author.username'])\n",
    "authors = list(set(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1040d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\n",
    "for word in list_of_words:\n",
    "    query+= word + \" OR \"\n",
    "query=query[:len(query)-4]\n",
    "\n",
    "query=\"(\"+query+\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3318fd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text= query\n",
    "queries_list=[]\n",
    "query_from_good=\"\"\n",
    "query_from_test=\"\"\n",
    "\n",
    "for author in authors:\n",
    "    query_from_test+=\"from: \" + author + \" OR \"\n",
    "    if len(query_text + query_from_test) + 3 <= 1024:\n",
    "        query_from_good = query_from_test\n",
    "    else:\n",
    "        queries_list.append(\"(\"+query_from_good[:len(query_from_good)-4]+\")\"+ query_text)\n",
    "        query_from_good=\"from: \" + author + \" OR \"\n",
    "        query_from_test=\"from: \" + author + \" OR \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489cb0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(queries_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77d143",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_data+sep+'final_search_for_tweets_df.txt', 'w') as f:\n",
    "    for line in queries_list:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f276b622",
   "metadata": {},
   "source": [
    "**Manual revision:** Run the following two cells to know the total number of tweets to download and see if does not exceed the limit of your twarc acount. If is OK run also the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=path_data+sep+'final_search_for_tweets_df.txt'\n",
    "%cd {path_data}\n",
    "! twarc2 searches --archive --counts-only --granularity day --start-time {start_date} --end-time {end_date} {file} final_search_count.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41600c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=pd.read_csv(path_data+sep+'final_search_count.csv',encoding = \"ISO-8859-1\")\n",
    "print(\"Tweets to download: \"+str(count['day_count'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b00cef",
   "metadata": {},
   "source": [
    "**Download the tweets:** (Only if you have enought limit in your twarc account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d86fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {path_data}\n",
    "! twarc2 searches --archive --start-time {start_date} --end-time {end_date} {file} final_corpus_search.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
